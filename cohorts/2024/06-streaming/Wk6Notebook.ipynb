{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd99e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests requests_oauthlib kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247645b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/dpkp/kafka-python.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "server = 'localhost:9092'\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[server],\n",
    "    value_serializer=json_serializer\n",
    ")\n",
    "\n",
    "producer.bootstrap_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'test-topic'\n",
    "\n",
    "for i in range(10):\n",
    "    t1a = time.time()\n",
    "    message = {'number': i}\n",
    "    producer.send(topic_name, value=message)\n",
    "    print(f\"Sent: {message}\")\n",
    "    t1b = time.time()\n",
    "    print(f'Sending took {(t1b - t1a):.2f} seconds')\n",
    "    time.sleep(0.05)\n",
    "\n",
    "tPreFlush = time.time()\n",
    "producer.flush()\n",
    "tPostFlush = time.time()\n",
    "print(f'Flushing took {(tPostFlush - tPreFlush):.2f} seconds')\n",
    "\n",
    "tEnd = time.time()\n",
    "print(f'Total took {(tEnd - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802936ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'lpep_pickup_datetime' : str,\n",
    "          'lpep_dropoff_datetime' : str,\n",
    "         'PULocationID': int, \n",
    "         'DOLocationID': int, \n",
    "         'passenger_count': int, \n",
    "         'trip_distance': float, \n",
    "         'tip_amount': float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46839d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['lpep_pickup_datetime','lpep_dropoff_datetime','PULocationID', 'DOLocationID','passenger_count', 'trip_distance','tip_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdee3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =  ['lpep_pickup_datetime','lpep_dropoff_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "pyspark_version = pyspark.__version__\n",
    "kafka_jar_package = f\"org.apache.spark:spark-sql-kafka-0-10_2.12:{pyspark_version}\"\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"GreenTripsConsumer\") \\\n",
    "    .config(\"spark.jars.packages\", kafka_jar_package) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('green_tripdata_2019-10.csv.gz', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Add the timestamp column using current_timestamp function\n",
    "df_with_timestamp = df.withColumn('timestamp', F.current_timestamp())\n",
    "\n",
    "\n",
    "# Convert the pyspark dataframe to pandas dataframe\n",
    "pandas_df = df_with_timestamp.toPandas()\n",
    "\n",
    "# Convert the timestamp column to string\n",
    "pandas_df['timestamp'] = pandas_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d787dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for row in pandas_df.itertuples(index=False):\n",
    "    row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "    print(row_dict)    \n",
    "    producer.send('green-trips', value=row_dict)\n",
    "    \n",
    "producer.flush()\n",
    "\n",
    "tEnd = time.time()\n",
    "print(f'Total took {(tEnd - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93229d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:8080\") \\\n",
    "    .option(\"subscribe\", \"green-trips\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(mini_batch, batch_id):\n",
    "        first_row = mini_batch.take(1)\n",
    "    \n",
    "        if first_row:\n",
    "            display(first_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f6304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = green_stream.writeStream.foreachBatch(peek).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6206114",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77856003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0679b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType() \\\n",
    "    .add(\"lpep_pickup_datetime\", types.StringType()) \\\n",
    "    .add(\"lpep_dropoff_datetime\", types.StringType()) \\\n",
    "    .add(\"PULocationID\", types.IntegerType()) \\\n",
    "    .add(\"DOLocationID\", types.IntegerType()) \\\n",
    "    .add(\"passenger_count\", types.DoubleType()) \\\n",
    "    .add(\"trip_distance\", types.DoubleType()) \\\n",
    "    .add(\"tip_amount\", types.DoubleType()) \\\n",
    "    .add(\"timestamp\", types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4870d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "green_stream = green_stream \\\n",
    "  .select(F.from_json(F.col(\"value\").cast('STRING'), schema).alias(\"data\")) \\\n",
    "  .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = green_stream.writeStream.foreachBatch(peek).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"green-trips\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94410edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations = popular_destinations \\\n",
    "  .select(F.from_json(F.col(\"value\").cast('STRING'), schema).alias(\"data\")) \\\n",
    "  .select(\"data.*\");\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c51f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddestionations = popular_destinations.groupBy(\"DOLocationID\", \"timestamp\").count().orderBy(\"count\",  ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupeddestinations = groupeddestionations.orderBy(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a63421",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = groupeddestionations \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8d37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
